---
title: "How to keep reporting siloed in [!DNL Target] for native mobile A/B tests"
description: Description
solution: Target
product: Target
applies-to: "Target"
keywords: "KCS,Target,native mobile,A/B tests,QA,reporting"
resolution: Resolution
internal-notes: 
bug: False
article-created-by: Mihnea Docea
article-created-date: "5/5/2022 11:49:08 PM"
article-published-by: Jim Menn
article-published-date: "9/7/2022 5:14:25 PM"
version-number: 3
article-number: KA-14474
dynamics-url: "https://adobe-ent.crm.dynamics.com/main.aspx?forceUCI=1&pagetype=entityrecord&etn=knowledgearticle&id=5a7119f3-cdcc-ec11-a7b5-6045bd00dbbc"

---
# How to keep reporting siloed in [!DNL Target] for native mobile A/B tests

## Description


<b>Environment</b>
 Adobe Target

<b>Issue</b>
 What is the recommended approach for developing, testing, and releasing A/B tests for native mobile with Adobe Target so that test traffic does not impact production metrics?


## Resolution


<b>Solution</b>
Most mobile engineering teams use the same code base from dev, staging, QA, pre-prod, and prod.
To keep the reporting separate, you should change the mbox/location names of the dev app, or have a specific mbox parameter for dev builds that are not passing in the prod app.
For example, the dev team could pass a key-value pair for each environment, something like *env=dev, env=prod*.
A campaign should be set up in [!DNL Target] for each environment to keep reporting clean when QA happens.
So you could have a QA campaign setup on mbox location "QA", or with audience condition that checks for *env= QA*, and likewise do the same for a production campaign.
