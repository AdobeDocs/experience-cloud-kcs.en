---
title: "Understanding Fulltext search"
description: Description
solution: Experience Manager as a Cloud Service,Experience Manager
product: Experience Manager as a Cloud Service,Experience Manager
applies-to: "Experience Manager as a Cloud Service,Experience Manager 6.5"
keywords: "KCS, Index, Indexing, Search, Fulltext search, Fulltext"
resolution: Resolution
internal-notes: 
bug: False
article-created-by: Cedric Latimier
article-created-date: "7/26/2023 2:18:55 PM"
article-published-by: Cedric Latimier
article-published-date: "7/26/2023 3:52:28 PM"
version-number: 1
article-number: KA-22521
dynamics-url: "https://adobe-ent.crm.dynamics.com/main.aspx?forceUCI=1&pagetype=entityrecord&etn=knowledgearticle&id=17e28958-bf2b-ee11-bdf4-6045bd006239"

---
# Understanding Fulltext search

## Description {#description}

This article applies to Apache Lucene, ElasticSearch, as well as fulltext indexes of e.g. PostgreSQL, SQLite, MySQL. 
<br>The following example is for AEM / Oak / Lucene.<br><br> <br><br><b>Data to be indexed</b><br><br> <br><br>It starts with the data that needs to be indexed. Let's say we have the following documents<br><br> <br><br><br>

| <b>Document ID</b> | <b>Path</b> | <b>Fulltext</b> |
| --- | --- | --- |
| 100 | /content/rubik | "Rubik is a Finnish brand." |
| 200 | /content/rubiksCube | "The Rubik's Cube was invented in 1974." |
| 300 | /content/cube | "A cube is a 3-dimensional object." |


<b>Inverted index</b>

The indexing mechanism splits the fulltext into words (called "tokens") and builds an index (called "inverted index" for some reason). This index contains, for each word, the list of documents where it appears. 
 Very short, common words ("stopwords") are not indexed. All tokens are converted to lowercase, and stemming is applied (converting e.g. plural to singular).
 Notice special characters such as "-" are not indexed.


| <b>Token</b> | <b>Document IDs</b> |
| --- | --- |
| 194 | ..., 200,... |
| brand | ..., 100,... |
| cube | ..., 200, 300,... |
| dimension | 300 |
| finnish | ..., 100,... |
| invent | 200 |
| object | ..., 300,... |
| rubik | .., 100, 200,... |


Notice the list of documents is sorted. This will become handy when querying.

<b>Searching</b>

Now we search (notice we replaced all special characters such as ' with a space):

/jcr:root/content//element(\*; cq:Page)`[` jcr:contains('Rubik s Cube')`]`

The words are tokenized and filtered in the same way as when indexing (single character words removed for example). So we search for:

+:fulltext:rubik +:fulltext:cube

The index will then consult the list of documents for those words. If there are lots of documents, the lists can be very large. Let's say they contains the following:


| <b>Token</b> | <b>Document IDs</b> |
| --- | --- |
| rubik | 10, 100, 200, 1000 |
| cube | 30, 200, 300, 2000 |


Now, Lucene will flip back-and-forth between the two lists (or round-robin n lists, when searching for n words):

- Read in the "rubik" get the first entry: we find 10
- Read in the "cube" get the first entry `>` = 10. 10 is not found, then the next one is 30.
- Read in the "rubik" get the first entry `>` = 30: we find 100.
- Read in the "cube" get the first entry `>` = 100: we find 200.
- Read in the "rubik" get the first entry `>` = 200. 200 is found! So document 200 ist a match for both terms! This is remembered.
- Read in the "rubik" get the next entry: 1000.
- Read in the "cube" get the first entry `>` = 1000: we find 2000.
- Read in the "rubik" get the first entry `>` = 2000: end of the list.
- Now we can stop.


So the only document found that contains both terms is 200, the document


| 200 | /content/rubiksCube | "The Rubik's Cube was invented in 1974." |
| --- | --- | --- |





## Resolution {#resolution}

When multiple entries are found, they are then sorted by score, which is not described here. 