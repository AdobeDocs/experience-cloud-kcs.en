---
title: Understanding caching directories
description: Description
solution: Experience Manager
product: Experience Manager
applies-to: Experience Manager
keywords: KCS, understand caching directories, AEM, Adobe Experience Manager, Best Practices
resolution: Resolution
internal-notes: null
bug: false
article-created-by: Jim Menn
article-created-date: 5/9/2023 1:25:44 PM
article-published-by: Jim Menn
article-published-date: 5/9/2023 1:34:49 PM
version-number: 8
article-number: KA-17912
dynamics-url: https://adobe-ent.crm.dynamics.com/main.aspx?forceUCI=1&pagetype=entityrecord&etn=knowledgearticle&id=746780fb-6cee-ed11-8849-6045bd006b3d
exl-id: a5da3fc9-c0a0-4d5a-8369-a96dad9e2b49
---
# Understanding caching directories

## Description {#description}


<b>Environment</b>
 Adobe Experience Manager

<b>Issue/Symptoms</b>
 This document explains how dispatcher caching happens and how it can be configured.
[Table of contents](https://experienceleague.adobe.com/docs/experience-cloud-kcs/kbarticles/KA-17490.html)

## Resolution {#resolution}


<b>Caching Directories</b>

We use the following default cache directories in our baseline installations

- Author

    - /mnt/var/www/author
- Publisher

    - /mnt/var/www/html


When each request traverses the dispatcher, the requests follow the configured rules to keep a locally cached version of the response of eligible items.

<b>Note:</b>

We intentionally keep the published workload separate from the author workload because when Apache looks for a file in the DocumentRoot, it doesn’t know which AEM instance it came from. So even if you have cache disabled in the author farm, if the author’s DocumentRoot is the same as the publisher, it will serve files from the cache when present. Meaning you’ll serve author files from the published cache and make for a really awful mix-match experience for your visitors. Keeping separate DocumentRoot directories for different published content is also a very bad idea. You’ll have to create multiple re-cached items that don’t differ between sites like clientlibs, as well as having to set up a replication flush agent for each DocumentRoot you set up—increasing the amount of flush overhead with each page activation. Rely on the namespace of files and their full cached paths and avoid multiple DocumentRoots for published sites.



<b>Configuration Files</b>

Dispatcher controls what qualifies as cacheable in the /cache section of any farm file. 
In the AMS baseline configuration farms, you'll find our includes like shown below:


```
/cache { 
    /rules { 
        $include "/etc/httpd/conf.dispatcher.d/cache/ams_author_cache.any" 
    }
```


When creating the rules for what to cache or not, please refer to the documentation [here](https://experienceleague.adobe.com/docs/experience-manager-dispatcher/using/configuring/dispatcher-configuration.html?lang=en#configuring-the-dispatcher-cache-cache)



<b>Caching author</b>

There are a lot of implementations we've seen where people don't cache author content. 
They are missing out on a huge upgrade in performance and responsiveness to their authors.

Let's discuss the strategy taken in configuring our author farm to cache properly.

Here is a base author /cache section of our author farm file:


```
/cache { 
    /docroot "/mnt/var/www/author" 
    /statfileslevel "2" 
    /allowAuthorized "1" 
    /rules { 
        $include "/etc/httpd/conf.dispatcher.d/cache/ams_author_cache.any" 
    } 
    /invalidate { 
        /0000 { 
            /glob "*" 
            /type "allow" 
        } 
    } 
    /allowedClients { 
        /0000 { 
            /glob "*.*.*.*" 
            /type "deny" 
        } 
        $include "/etc/httpd/conf.dispatcher.d/cache/ams_author_invalidate_allowed.any" 
    } 
}
```


The important things to note here are that the <b>/docroot</b> is set to the cache directory for the author.

<b>Note:</b>

Make sure your DocumentRoot in the author's .vhost file matches the farms /docroot parameter.

The cache rules include statement includes the file <b>/etc/httpd/conf.dispatcher.d/cache/ams_author_cache.any</b> which contains these rules:


```
/0000 { 
 /glob "*" 
 /type "deny" 
} 
/0001 { 
 /glob "/libs/*" 
 /type "allow" 
} 
/0002 { 
 /glob "/libs/*.html" 
 /type "deny" 
} 
/0003 { 
 /glob "/libs/granite/csrf/token.json" 
 /type "deny" 
} 
/0004 { 
 /glob "/apps/*" 
 /type "allow" 
} 
/0005 { 
 /glob "/apps/*.html" 
 /type "deny" 
} 
/0006 { 
 /glob "/libs/cq/core/content/welcome.*" 
 /type "deny" 
}
```


In an author scenario, content is changing all the time and on purpose. You only want to cache items that are not going to change frequently.
We have rules to cache /libs because they are part of the baseline AEM install and would change until you have installed a Service Pack, Cumulative Fix Pack, Upgrade, or Hotfix. Caching these elements makes a ton of sense and really benefits the authoring experience of end users who use the site.

<b>Note:</b>

Keep in mind that these rules also cache <b>/apps</b> this is where custom application code lives. If you're developing your code on this instance, then it will prove to be very confusing when you save your file and don't see if it reflects in the UI due to it serving up a cached copy. The intention here is that if you do a deployment of your code into AEM, it too would be infrequent, and part of your deployment steps should be to clear the author cache. Again the benefit is huge, making your cacheable code run faster for the end users.



<b>ServeOnStale (AKA Serve on Stale / SOS)</b>

This is one of those gems of a feature of the dispatcher. If the publisher is under load or has become unresponsive, it will typically throw a 502 or 503 http response code. If that happens and this feature is enabled, the dispatcher will be instructed to still serve whatever content is still in the cache as a best effort, even if it’s not a fresh copy. It’s better to serve something if you’ve got it rather than just showing an error message that offers no functionality.

<b>Note:</b>

Keep in mind that if the publisher renderer has a socket timeout or 500 error message, this feature will not trigger. If AEM is just unreachable, this feature does nothing.

This setting can be set on any farm, but applying it to the published farm files only makes sense. Here is a syntax example of the feature enabled in a farm file:


```
/cache { 
    /serveStaleOnError "1"
```




<b>Caching pages with Query params / Arguments</b>

<b>Note:</b>

One of the normal behaviors of the Dispatcher module is that if a request has a query parameter in the URI (typically shown like /content/page.html<b>?myquery=value</b>) it will skip caching the file and go directly to the AEM instance. It’s considering this request a dynamic page and shouldn’t be cached. This can cause an ill effect on cache efficiency.

If you have pages in AEM that take GET arguments/query parameters in the address line that help the page operate but don’t render different HTML are good candidates for this configuration element.

You can tell the dispatcher which arguments to ignore and still cache the page.

As an example, someone has built a social media deep link reference mechanism that uses the argument reference in the URI to know where the person came from.

<b>Example usage:</b>

[https://www.retail.com/home.html?reference=android](https://www.retail.com/home.html?reference=android)

[https://www.retail.com/home.html?reference=facebook](https://www.retail.com/home.html?reference=facebook)

The page is 100% cacheable but doesn't cache because the arguments are present. 
To work around this, we add the following section to our farm configuration file:


```
/cache { 
    /ignoreUrlParams { 
        /0001 { /glob "*" /type "deny" } 
        /0002 { /glob "reference" /type "allow" } 
    }
```


Now when the dispatcher sees the request, it will ignore the fact that the request has the query parameter of reference and still cache the page.



<b>Caching response headers</b>

It’s pretty obvious that the dispatcher caches .html pages and clientlibs, but did you know it can also cache particular response headers alongside the content in a file with the same name but a .h file extension? This allows the next response to not only the content but the response headers that should go with it from the cache.

AEM can handle more than just UTF-8 encoding.

Sometimes items have special headers that help control cache TTL’s encoding details and last modified timestamps.

These values, when cached, are stripped by default, and the apache httpd web server will do its own job of processing the asset with its normal file handling methods, which normally is limited to mime type guessing based on file extensions.

If you have the dispatcher cache the asset and the desired headers, you can expose the proper experience and ensure that all the details make it to the clients' browser.

Here is an example of a farm with the headers to cache specified:


```
/cache { 
 /headers { 
  "Cache-Control" 
  "Content-Disposition" 
  "Content-Type" 
  "Expires" 
  "Last-Modified" 
  "X-Content-Type-Options" 
 } 
}
```


In the example, they have configured AEM to serve up headers the CDN looks for to know when to invalidate its cache. Meaning now AEM can properly dictate which files get invalidated based on headers.

<b>Note:</b>

Keep in mind you cannot use regular expressions or glob matching. It's a literal list of the headers to cache. Only put in a list of the literal headers you want it to cache.



<b>Auto-Invalidate Grace Period</b>

On AEM systems that have a lot of activity from authors that do a lot of page activations, you can have a race condition where repeat invalidations occur. Heavily repeated flush requests are unnecessary, and you can build in some tolerance to not repeat a flush until the grace period has cleared.

<b>Example of how this works:</b>

If you have five requests to invalidate /content/exampleco/en/, all happen within a 3 second period.

With this feature off you'd invalidate the cache directory /content/exampleco/en/ 5 times.

With this feature on and set to 5 seconds, it would invalidate the cache directory /content/exampleco/en/once.

Here is an example syntax of this feature being configured for 5 second grace period:


```
/cache { 
    /gracePeriod "5"
```




<b>TTL Based Invalidation</b>

A newer feature of the dispatcher module was <b>Time To Live (TTL)</b> based invalidation options for cached items. When an item gets cached, it looks for the presence of cache control headers and generates a file in the cache directory with the same name and a <b>.ttl</b> extension.

Here is an example of the feature being configured in the farm configuration file:


```
/cache { 
    /enableTTL "1"
```


<b>Note:</b>

Keep in mind that AEM still needs to be configured to send TTL headers for the dispatcher to honor them. Toggling this feature only enables the dispatcher to know when to remove the files that AEM has sent cache control headers for. If AEM doesn’t start sending TTL headers, then the dispatcher won’t do anything special here.



<b>Cache Filter Rules</b>

Here is an example of a baseline configuration for which elements to cache on a publisher:


```
/cache{ 
    /0000 { 
        /glob "*" 
        /type "allow" 
    } 
    /0001 { 
        /glob "/libs/granite/csrf/token.json" 
        /type "deny" 
    }
```


We want to make our published site greedy as possible and cache everything.

If there are elements that break the experience when cached, you can add rules to remove the option to cache that item. As you see in the example above the, csrf tokens shouldn't ever be cached and have been excluded. Further details on writing these rules can be found [here](https://experienceleague.adobe.com/docs/experience-manager-dispatcher/using/configuring/dispatcher-configuration.html?lang=en#configuring-the-dispatcher-cache-cache).
